{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa0cf049",
   "metadata": {},
   "source": [
    "# IV Surface Generation Pipeline\n",
    "## Arbitrage-Free IV Surfaces using Conditional VAE\n",
    "\n",
    "This notebook orchestrates the complete pipeline for generating arbitrage-free volatility surfaces:\n",
    "\n",
    "1. **Single Heston Calibration** - Fits Heston model parameters for each day\n",
    "2. **Conditional VAE Training** - Trains the conditional VAE with market conditioning\n",
    "3. **IV Surface Generation** - Generates surfaces for specific dates\n",
    "\n",
    "---\n",
    "\n",
    "**Status:** Ready to run (all dependencies installed, data prepared)\n",
    "**Data Range:** 2019-01-01 to 2025-11-10\n",
    "**Latest GDELT Data:** 2025-11-10 \n",
    "\n",
    "---\n",
    "\n",
    "###  File Operations Summary\n",
    "\n",
    "**Read-Only Operations (Safe):**\n",
    "-  Section 4 & 5: IV Surface Generation & Visualization - Only reads from existing models/data\n",
    "-  Section 8: Results Management - Only reads and displays results\n",
    "\n",
    "**Write Operations (Modifies Original Files):**\n",
    "-  **Section 2**: Heston Calibration writes to `calibration_single_heston/`\n",
    "  - Skip this section to use existing calibration results\n",
    "-  **Section 3**: CVAE Training writes to `condtional_vae/best_model/`\n",
    "  - Keep `RUN_CVAE_TRAINING = False` to use existing pre-trained model\n",
    "\n",
    "**Notebook Output Location:**\n",
    "-  All notebook-generated results are saved to `demo_results/` folder\n",
    "-  Original data files and models remain unchanged (unless you run Sections 2 or 3)\n",
    "\n",
    "**Recommendation:** For a demo run, skip Sections 2 & 3 and only run Sections 4-5 to generate surfaces using existing models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad485ce",
   "metadata": {},
   "source": [
    "##  Quick Start Guide for TAs/Reviewers\n",
    "\n",
    "### Prerequisites Check\n",
    "\n",
    "Before running this notebook, ensure:\n",
    "\n",
    "1. **Python Environment**: Virtual environment with all dependencies installed\n",
    "   ```bash\n",
    "   source .venv/bin/activate  # Activate the virtual environment\n",
    "   ```\n",
    "\n",
    "2. **Required Files** (should already exist in project):\n",
    "   -  `nifty_filtered_surfaces.pickle` - Input IV surface data\n",
    "   -  `calibration_single_heston/NIFTY_heston_single_params_tensor.pt` - Pre-computed Heston parameters\n",
    "   -  `llm_options_assistant/best_model_2025/cvae_model.pt` - Pre-trained CVAE model\n",
    "   -  `api.json` - Gemini API key for LLM assistant\n",
    "\n",
    "3. **Dependencies**: All packages from `requirements.txt` should be installed\n",
    "\n",
    "### Recommended Demo Workflow (5-10 minutes)\n",
    "\n",
    "**For a quick demo without re-training:**\n",
    "\n",
    "1. **Run Section 1**: Setup and Environment \n",
    "2. **Skip Section 2**: Uses existing Heston calibration \n",
    "3. **Skip Section 3**: Uses pre-trained CVAE model \n",
    "4. **Run Section 4**: Generate IV surfaces for a date (takes ~1 minute) \n",
    "5. **Run Section 5**: View results and visualizations \n",
    "6. **Optional - Run Section 7**: Chat with LLM assistant (requires API key)\n",
    "\n",
    "**Output Location**: All results saved to `demo_results/` folder\n",
    "\n",
    "### Full Pipeline (if time permits - 30+ minutes)\n",
    "\n",
    "Run all sections sequentially to see the complete training pipeline:\n",
    "- Section 2: Heston Calibration (~10-30 minutes)\n",
    "- Section 3: CVAE Training (~10-30 minutes)\n",
    "- Sections 4-5: Surface Generation & Visualization\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Issue**: Module not found errors\n",
    "- **Solution**: Ensure virtual environment is activated\n",
    "\n",
    "**Issue**: File not found errors\n",
    "- **Solution**: Check that you're in the project root directory\n",
    "\n",
    "**Issue**: LLM Assistant not working\n",
    "- **Solution**: API key in `api.json` is optional for demo. Skip Section 7 if not needed.\n",
    "\n",
    "### What This Notebook Demonstrates\n",
    "\n",
    "1. **Heston Model Calibration**: Fits stochastic volatility model to market data\n",
    "2. **Conditional VAE**: Learns distribution of Heston parameters conditioned on market variables\n",
    "3. **IV Surface Generation**: Generates arbitrage-free volatility surfaces for any date\n",
    "4. **AI Analysis**: Interactive LLM assistant for options analysis (optional)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44353117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependency and Environment Check\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENVIRONMENT & DEPENDENCY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"\\n Python Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check if in virtual environment\n",
    "in_venv = hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)\n",
    "if in_venv:\n",
    "    print(f\" Virtual Environment: Active ({sys.prefix})\")\n",
    "else:\n",
    "    print(f\" Virtual Environment: Not detected\")\n",
    "    print(f\"  Run: source .venv/bin/activate\")\n",
    "\n",
    "# Check critical dependencies\n",
    "critical_packages = [\n",
    "    'torch', 'numpy', 'pandas', 'matplotlib', \n",
    "    'scipy', 'sklearn', 'tqdm', 'google.generativeai'\n",
    "]\n",
    "\n",
    "missing_packages = []\n",
    "print(f\"\\n Checking Dependencies:\")\n",
    "for package in critical_packages:\n",
    "    try:\n",
    "        if package == 'sklearn':\n",
    "            __import__('sklearn')\n",
    "        elif package == 'google.generativeai':\n",
    "            __import__('google.generativeai')\n",
    "        else:\n",
    "            __import__(package)\n",
    "        print(f\"   {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"   {package} - NOT FOUND\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(f\"  Install with: pip install {' '.join(missing_packages)}\")\n",
    "else:\n",
    "    print(f\"\\n All critical dependencies installed!\")\n",
    "\n",
    "# Check for required data files\n",
    "print(f\"\\n Checking Required Data Files:\")\n",
    "project_root = Path.cwd()\n",
    "\n",
    "required_files = {\n",
    "    'Input Data': project_root / 'nifty_filtered_surfaces.pickle',\n",
    "    'Heston Params': project_root / 'calibration_single_heston' / 'NIFTY_heston_single_params_tensor.pt',\n",
    "    'Pre-trained Model': project_root / 'llm_options_assistant' / 'best_model_2025' / 'cvae_model.pt',\n",
    "    'API Key (Optional)': project_root / 'api.json'\n",
    "}\n",
    "\n",
    "all_required_exist = True\n",
    "for name, filepath in required_files.items():\n",
    "    if filepath.exists():\n",
    "        size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "        print(f\"   {name:20s} ({size_mb:.1f} MB)\")\n",
    "    else:\n",
    "        if 'Optional' in name:\n",
    "            print(f\"   {name:20s} (Optional - skip Section 7 if missing)\")\n",
    "        else:\n",
    "            print(f\"   {name:20s} - NOT FOUND\")\n",
    "            all_required_exist = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if all_required_exist and not missing_packages:\n",
    "    print(\" READY TO RUN! All requirements satisfied.\")\n",
    "    print(\"   Proceed to Section 1 to start the pipeline.\")\n",
    "else:\n",
    "    print(\"  SETUP INCOMPLETE - Please address the issues above.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48113359",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INITIALIZING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"[1/3] Setting up paths...\", end=\" \")\n",
    "\n",
    "# Get the project root directory using relative path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"condtional_vae\" else Path.cwd()\n",
    "PROJECT_ROOT = PROJECT_ROOT.resolve()\n",
    "\n",
    "# Create results folder if it doesn't exist - NOTEBOOK OUTPUTS ONLY\n",
    "RESULTS_FOLDER = PROJECT_ROOT / \"demo_results\"\n",
    "RESULTS_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\")\n",
    "print(\"[2/3] Changing to project root...\", end=\" \")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(\"\")\n",
    "\n",
    "print(\"[3/3] Gathering environment info...\", end=\" \")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Use current Python executable (works in any environment)\n",
    "PYTHON_EXECUTABLE = sys.executable\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IV SURFACE GENERATION PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Project Root: {PROJECT_ROOT}\")\n",
    "print(f\"Results Folder: {RESULTS_FOLDER}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"Python Executable: {PYTHON_EXECUTABLE}\")\n",
    "print(f\"Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)\n",
    "print(\" Setup complete - ready to run scripts\\n\")\n",
    "print(\"\\n  IMPORTANT: This notebook only writes to demo_results/ folder\")\n",
    "print(\"   All original data files and models remain unchanged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[SETUP] Defining helper function...\", end=\" \")\n",
    "\n",
    "def run_script(script_path, script_name, description, timeout=None):\n",
    "    \"\"\"\n",
    "    Execute a Python script as subprocess and capture output.\n",
    "    Also saves output to a log file in the results folder.\n",
    "    \n",
    "    Args:\n",
    "        script_path: Full path to the Python script\n",
    "        script_name: Display name for the script\n",
    "        description: What the script does\n",
    "        timeout: Timeout in seconds (None for no timeout)\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (return_code, stdout, stderr)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Running: {script_name}\")\n",
    "    print(f\"Description: {description}\")\n",
    "    print(f\"Script: {script_path}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if not os.path.exists(script_path):\n",
    "        print(f\" ERROR: Script not found at {script_path}\")\n",
    "        return -1, \"\", f\"Script not found: {script_path}\"\n",
    "    \n",
    "    # Create log file in results folder\n",
    "    log_filename = f\"{script_name.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "    log_file = RESULTS_FOLDER / log_filename\n",
    "    \n",
    "    try:\n",
    "        # Use current Python executable (works in any environment)\n",
    "        python_exec = PYTHON_EXECUTABLE\n",
    "        \n",
    "        # Set up environment with proper matplotlib backend for non-interactive use\n",
    "        env = os.environ.copy()\n",
    "        env['MPLBACKEND'] = 'Agg'  # Use Agg backend (non-interactive, works in subprocess)\n",
    "        \n",
    "        print(\"[1/4] Preparing environment...\", end=\" \")\n",
    "        print(\"\")\n",
    "        \n",
    "        print(\"[2/4] Starting subprocess...\", end=\" \")\n",
    "        result = subprocess.run(\n",
    "            [python_exec, script_path],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=timeout,\n",
    "            cwd=os.path.dirname(script_path),\n",
    "            env=env  # Pass custom environment\n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        # Save output to log file\n",
    "        print(\"[3/4] Saving execution log...\", end=\" \")\n",
    "        with open(log_file, 'w') as f:\n",
    "            f.write(f\"Script: {script_name}\\n\")\n",
    "            f.write(f\"Description: {description}\\n\")\n",
    "            f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "            if result.stdout:\n",
    "                f.write(\"STDOUT:\\n\")\n",
    "                f.write(result.stdout)\n",
    "                f.write(\"\\n\\n\")\n",
    "            if result.stderr:\n",
    "                f.write(\"STDERR:\\n\")\n",
    "                f.write(result.stderr)\n",
    "                f.write(\"\\n\\n\")\n",
    "            f.write(f\"Return Code: {result.returncode}\\n\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Print output\n",
    "        print(\"[4/4] Processing results...\", end=\" \")\n",
    "        if result.stdout:\n",
    "            print(\"\")\n",
    "            print(result.stdout)\n",
    "        else:\n",
    "            print(\"\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\", result.stderr)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"\\n {script_name} completed successfully!\")\n",
    "            print(f\" Log saved to: {log_file}\")\n",
    "        else:\n",
    "            print(f\"\\n {script_name} exited with code {result.returncode}\")\n",
    "            print(f\" Log saved to: {log_file}\")\n",
    "        \n",
    "        return result.returncode, result.stdout, result.stderr\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\" ERROR: {script_name} timed out after {timeout} seconds\")\n",
    "        return -1, \"\", f\"Timeout after {timeout}s\"\n",
    "    except Exception as e:\n",
    "        print(f\" ERROR: {str(e)}\")\n",
    "        return -1, \"\", str(e)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9165a436",
   "metadata": {},
   "source": [
    "## Section 2: Single Heston Calibration\n",
    "\n",
    "Fits a single Heston model per day across all strikes and maturities.\n",
    "\n",
    "**Input:** `nifty_filtered_surfaces.pickle` (IV surfaces for NIFTY options)\n",
    "**Output:** \n",
    "- `calibration_single_heston/NIFTY_heston_single_params.pickle` (parameters)\n",
    "- `calibration_single_heston/NIFTY_heston_single_params_tensor.pt` (PyTorch tensor)\n",
    "\n",
    "**Process:**\n",
    "1. Stage 1: Fast calibration without Wasserstein penalty\n",
    "2. Stage 2: Refinement with Wasserstein penalty\n",
    "3. Validation: Feller condition, parameter bounds, arbitrage checks\n",
    "\n",
    "** WARNING:** Running this cell will write calibration results to `calibration_single_heston/` folder.\n",
    "If you want to preserve existing calibration results, skip this cell and use the existing files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e154d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Single Heston Calibration with real-time progress\n",
    "script_path = PROJECT_ROOT / \"calibration_single_heston\" / \"run_single_heston_calibration.py\"\n",
    "\n",
    "# Check if calibration results already exist\n",
    "output_pickle = PROJECT_ROOT / \"calibration_single_heston\" / \"NIFTY_heston_single_params.pickle\"\n",
    "output_tensor = PROJECT_ROOT / \"calibration_single_heston\" / \"NIFTY_heston_single_params_tensor.pt\"\n",
    "output_plot = PROJECT_ROOT / \"calibration_single_heston\" / \"heston_single_calibration_errors.png\"\n",
    "\n",
    "if output_pickle.exists() and output_tensor.exists():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"HESTON CALIBRATION - USING EXISTING RESULTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n Found existing calibration results:\")\n",
    "    print(f\"  {'Pickle':20s} {str(output_pickle):60s} \")\n",
    "    print(f\"  {'Tensor':20s} {str(output_tensor):60s} \")\n",
    "    print(f\"  {'Plot':20s} {str(output_plot):60s} {'' if output_plot.exists() else ''}\")\n",
    "    print(\"\\nSkipping calibration. To re-run calibration, delete these files and run this cell again.\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Running: Single Heston Calibration\")\n",
    "    print(\"Description: Fits Heston model parameters for each day (two-stage: fast + Wasserstein refinement)\")\n",
    "    print(f\"Script: {script_path}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if not script_path.exists():\n",
    "        print(f\" ERROR: Script not found at {script_path}\")\n",
    "    else:\n",
    "        # Use current Python executable\n",
    "        python_exec = PYTHON_EXECUTABLE\n",
    "        \n",
    "        # Set up environment with proper matplotlib backend\n",
    "        env = os.environ.copy()\n",
    "        env['MPLBACKEND'] = 'Agg'\n",
    "        \n",
    "        # Create log file\n",
    "        log_filename = f\"Single_Heston_Calibration_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "        log_file = RESULTS_FOLDER / log_filename\n",
    "        \n",
    "        try:\n",
    "            print(\"\\n[1/3] Starting calibration process...\")\n",
    "            print(\"[2/3] Running script with real-time output...\\n\")\n",
    "            \n",
    "            # Use Popen for real-time output streaming\n",
    "            process = subprocess.Popen(\n",
    "                [python_exec, str(script_path)],\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                text=True,\n",
    "                bufsize=1,  # Line buffered\n",
    "                cwd=str(script_path.parent),\n",
    "                env=env\n",
    "            )\n",
    "            \n",
    "            # Capture output for logging while displaying in real-time\n",
    "            output_lines = []\n",
    "            \n",
    "            # Stream output line by line\n",
    "            for line in process.stdout:\n",
    "                print(line, end='')  # Print immediately (real-time)\n",
    "                output_lines.append(line)\n",
    "            \n",
    "            # Wait for process to complete\n",
    "            return_code = process.wait()\n",
    "            \n",
    "            print(\"\\n[3/3] Saving execution log...\", end=\" \")\n",
    "            \n",
    "            # Save to log file\n",
    "            with open(log_file, 'w') as f:\n",
    "                f.write(f\"Script: Single Heston Calibration\\n\")\n",
    "                f.write(f\"Description: Fits Heston model parameters for each day\\n\")\n",
    "                f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                f.write(\"OUTPUT:\\n\")\n",
    "                f.write(''.join(output_lines))\n",
    "                f.write(f\"\\n\\nReturn Code: {return_code}\\n\")\n",
    "            \n",
    "            print(\"\")\n",
    "            \n",
    "            # Check if successful\n",
    "            if return_code == 0:\n",
    "                print(\"\\n Heston calibration completed successfully!\")\n",
    "                print(f\" Log saved to: {log_file}\")\n",
    "                \n",
    "                # Check output files\n",
    "                print(\"\\nOutput files:\")\n",
    "                print(f\"  {'Pickle':20s} {str(output_pickle):60s} {'' if output_pickle.exists() else ''}\")\n",
    "                print(f\"  {'Tensor':20s} {str(output_tensor):60s} {'' if output_tensor.exists() else ''}\")\n",
    "                print(f\"  {'Plot':20s} {str(output_plot):60s} {'' if output_plot.exists() else ''}\")\n",
    "            else:\n",
    "                print(f\"\\n Heston calibration failed with return code {return_code}\")\n",
    "                print(f\" Log saved to: {log_file}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" ERROR: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f464b",
   "metadata": {},
   "source": [
    "## Section 3: Conditional VAE Training (Optional)\n",
    "\n",
    "Trains the Conditional VAE with market conditioning variables.\n",
    "\n",
    "**Input:** \n",
    "- `calibration_single_heston/NIFTY_heston_single_params_tensor.pt` (Heston parameters)\n",
    "- Market data: India VIX, USD/INR, Crude Oil, US 10Y Yield\n",
    "- GDELT unrest index\n",
    "\n",
    "**Output:**\n",
    "- `condtional_vae/best_model/` (trained model weights)\n",
    "- Training curves, loss plots\n",
    "\n",
    "**Note:** This is optional - a pre-trained model is available at `llm_options_assistant/best_model_2025/`\n",
    "\n",
    "** WARNING:** Running training will write model files to `condtional_vae/best_model/` folder.\n",
    "If you want to preserve existing trained models, keep `RUN_CVAE_TRAINING = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fa11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run CVAE training (takes 10-30 minutes)\n",
    "# This is optional - a pre-trained model exists\n",
    "\n",
    "RUN_CVAE_TRAINING = False\n",
    "\n",
    "if RUN_CVAE_TRAINING:\n",
    "    # Check if Heston calibration parameters exist\n",
    "    heston_tensor = PROJECT_ROOT / \"calibration_single_heston\" / \"NIFTY_heston_single_params_tensor.pt\"\n",
    "    \n",
    "    if not heston_tensor.exists():\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ERROR: Heston Calibration Parameters Not Found\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\nRequired file missing: {heston_tensor}\")\n",
    "        print(\"\\nCVAE training requires Heston parameters as input.\")\n",
    "        print(\"\\nOptions:\")\n",
    "        print(\"  1. Run Section 2 (Heston Calibration) first\")\n",
    "        print(\"  2. Or ensure the file exists from a previous calibration run\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"CVAE Training - Prerequisites Check\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\" Heston parameters found: {heston_tensor}\")\n",
    "        print(f\"  Using existing calibration results for training\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        script_path = PROJECT_ROOT / \"condtional_vae\" / \"train_cvae.py\"\n",
    "        \n",
    "        return_code, stdout, stderr = run_script(\n",
    "            script_path=str(script_path),\n",
    "            script_name=\"Conditional VAE Training\",\n",
    "            description=\"Trains the conditional VAE with market conditioning variables\",\n",
    "            timeout=None\n",
    "        )\n",
    "        \n",
    "        if return_code == 0:\n",
    "            print(\"\\n CVAE training completed successfully!\")\n",
    "            \n",
    "            # Check output files\n",
    "            model_dir = PROJECT_ROOT / \"condtional_vae\" / \"best_model\"\n",
    "            model_file = model_dir / \"cvae_model.pt\"\n",
    "            \n",
    "            if model_file.exists():\n",
    "                print(f\"\\n Trained model saved to: {model_file}\")\n",
    "                print(f\"  This model will now be used for IV surface generation.\")\n",
    "            else:\n",
    "                print(f\"\\n Warning: Model file not found at expected location: {model_file}\")\n",
    "        else:\n",
    "            print(f\"\\n CVAE training failed with return code {return_code}\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CVAE Training - SKIPPED\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Check for pre-trained model\n",
    "    pretrained_model = PROJECT_ROOT / \"llm_options_assistant\" / \"best_model_2025\" / \"cvae_model.pt\"\n",
    "    trained_model = PROJECT_ROOT / \"condtional_vae\" / \"best_model\" / \"cvae_model.pt\"\n",
    "    \n",
    "    if pretrained_model.exists():\n",
    "        print(f\"\\n Using pre-trained model: llm_options_assistant/best_model_2025/cvae_model.pt\")\n",
    "    elif trained_model.exists():\n",
    "        print(f\"\\n Using trained model: condtional_vae/best_model/cvae_model.pt\")\n",
    "    else:\n",
    "        print(f\"\\n No trained model found in either location:\")\n",
    "        print(f\"  - {pretrained_model}\")\n",
    "        print(f\"  - {trained_model}\")\n",
    "        print(f\"\\n  You will need to run training to generate IV surfaces.\")\n",
    "    \n",
    "    # Check if Heston parameters exist for potential training\n",
    "    heston_tensor = PROJECT_ROOT / \"calibration_single_heston\" / \"NIFTY_heston_single_params_tensor.pt\"\n",
    "    if heston_tensor.exists():\n",
    "        print(f\"\\n Heston calibration parameters available: {heston_tensor.name}\")\n",
    "        print(f\"  Ready for training if needed.\")\n",
    "    else:\n",
    "        print(f\"\\n Heston calibration parameters not found: {heston_tensor.name}\")\n",
    "        print(f\"  Run Section 2 (Heston Calibration) before training.\")\n",
    "    \n",
    "    print(\"\\nTo run training:\")\n",
    "    print(\"  1. Ensure Heston calibration is complete (Section 2)\")\n",
    "    print(\"  2. Set RUN_CVAE_TRAINING = True\")\n",
    "    print(\"  3. Re-run this cell\")\n",
    "    print(\"\\nNote: Training takes 10-30 minutes and requires Heston parameters as input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5481549",
   "metadata": {},
   "source": [
    "## Section 4: Generate IV Surfaces\n",
    "\n",
    "Generates IV surfaces for specific dates using the trained CVAE model.\n",
    "\n",
    "**Inputs:**\n",
    "- Date (format: YYYY-MM-DD)\n",
    "- Number of samples to generate (default: 100)\n",
    "- Pre-trained CVAE model\n",
    "- Market data: NIFTY spot, India VIX, USD/INR, Crude Oil, US 10Y Yield, GDELT unrest\n",
    "\n",
    "**Outputs:**\n",
    "- IV surface matrices (CSV)\n",
    "- Surface visualization plots (PNG)\n",
    "- PyTorch tensor data\n",
    "\n",
    "**Usage:**\n",
    "Define a date below, then run the cell to generate surfaces for that date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for IV Surface Generation\n",
    "TARGET_DATE = \"2025-11-10\"  # Change this to any date from 2015-01-01 to 2025-11-10\n",
    "N_SAMPLES = 100  # Number of surface samples to generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"IV SURFACE GENERATION CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Target Date: {TARGET_DATE}\")\n",
    "print(f\"Number of Samples: {N_SAMPLES}\")\n",
    "\n",
    "# Check for pre-trained model\n",
    "pretrained_model = PROJECT_ROOT / \"llm_options_assistant\" / \"best_model_2025\" / \"cvae_model.pt\"\n",
    "trained_model = PROJECT_ROOT / \"condtional_vae\" / \"best_model\" / \"cvae_model.pt\"\n",
    "\n",
    "if pretrained_model.exists():\n",
    "    print(f\"Model: llm_options_assistant/best_model_2025/cvae_model.pt \")\n",
    "    MODEL_PATH = pretrained_model\n",
    "elif trained_model.exists():\n",
    "    print(f\"Model: condtional_vae/best_model/cvae_model.pt \")\n",
    "    MODEL_PATH = trained_model\n",
    "else:\n",
    "    print(f\"Model:  No trained model found!\")\n",
    "    print(f\"  Expected locations:\")\n",
    "    print(f\"    - {pretrained_model}\")\n",
    "    print(f\"    - {trained_model}\")\n",
    "    print(f\"\\n  Please run Section 3 (CVAE Training) first or ensure pre-trained model exists.\")\n",
    "    MODEL_PATH = None\n",
    "\n",
    "print(f\"Available Date Range: 2015-01-01 to 2025-11-10\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd966a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run IV Surface Generator\n",
    "script_path = PROJECT_ROOT / \"condtional_vae\" / \"generate_iv_surface_by_date.py\"\n",
    "\n",
    "# Check if model exists (from previous cell)\n",
    "if 'MODEL_PATH' not in dir() or MODEL_PATH is None:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ERROR: No trained model available\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nPlease ensure one of the following:\")\n",
    "    print(\"  1. Pre-trained model exists at: llm_options_assistant/best_model_2025/cvae_model.pt\")\n",
    "    print(\"  2. Run Section 3 (CVAE Training) to train a new model\")\n",
    "    print(\"\\nCannot generate IV surfaces without a trained model.\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    # Use current Python executable\n",
    "    python_exec = PYTHON_EXECUTABLE\n",
    "\n",
    "    cmd = [\n",
    "        python_exec,\n",
    "        str(script_path),\n",
    "        \"--date\", TARGET_DATE,\n",
    "        \"--n_samples\", str(N_SAMPLES),\n",
    "        \"--output_dir\", \"results_date\"\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"Running: IV Surface Generation for {TARGET_DATE}\")\n",
    "        print(f\"Number of samples: {N_SAMPLES}\")\n",
    "        print(f\"Output will be saved to: {RESULTS_FOLDER}/{TARGET_DATE}_TIMESTAMP/\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Set up environment with proper matplotlib backend\n",
    "        env = os.environ.copy()\n",
    "        env['MPLBACKEND'] = 'Agg'  # Use Agg backend (non-interactive, works in subprocess)\n",
    "        \n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300,\n",
    "            cwd=str(PROJECT_ROOT / \"condtional_vae\"),\n",
    "            env=env  # Pass custom environment\n",
    "        )\n",
    "        \n",
    "        print(result.stdout)\n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\", result.stderr)\n",
    "        \n",
    "        # Create timestamped folder in demo_results\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        dated_results_dir = RESULTS_FOLDER / f\"{TARGET_DATE}_{timestamp}\"\n",
    "        dated_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy generated files from temporary location to demo_results folder\n",
    "        # The script writes to condtional_vae/results_date/ temporarily\n",
    "        source_dir = PROJECT_ROOT / \"condtional_vae\" / \"results_date\" / TARGET_DATE\n",
    "        \n",
    "        if source_dir.exists():\n",
    "            print(f\"\\n Copying results to demo_results: {dated_results_dir.name}\")\n",
    "            \n",
    "            # Copy all files from source to demo_results folder\n",
    "            for file in source_dir.glob(\"*\"):\n",
    "                if file.is_file():\n",
    "                    dest_file = dated_results_dir / file.name\n",
    "                    shutil.copy2(file, dest_file)\n",
    "                    size = file.stat().st_size / 1024\n",
    "                    print(f\"   Copied {file.name} ({size:.1f} KB)\")\n",
    "            \n",
    "            # Save execution log\n",
    "            log_file = dated_results_dir / f\"execution_log_{timestamp}.log\"\n",
    "            with open(log_file, 'w') as f:\n",
    "                f.write(f\"IV Surface Generation Report\\n\")\n",
    "                f.write(f\"Date: {TARGET_DATE}\\n\")\n",
    "                f.write(f\"Samples: {N_SAMPLES}\\n\")\n",
    "                f.write(f\"Executed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                f.write(\"STDOUT:\\n\")\n",
    "                f.write(result.stdout)\n",
    "                f.write(\"\\n\\nSTDERR:\\n\")\n",
    "                f.write(result.stderr)\n",
    "                f.write(f\"\\n\\nReturn Code: {result.returncode}\\n\")\n",
    "            \n",
    "            print(f\"   Saved execution log\")\n",
    "            print(f\"\\n All results saved to: {dated_results_dir}\")\n",
    "            \n",
    "            # Note about temporary files\n",
    "            print(f\"\\n Note: Script temporarily writes to condtional_vae/results_date/{TARGET_DATE}/\")\n",
    "            print(f\"   These files are copied to demo_results and can be safely deleted.\")\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                print(f\"\\n IV Surface generation completed successfully!\")\n",
    "            else:\n",
    "                print(f\"\\n Generation completed with warnings (return code {result.returncode})\")\n",
    "        else:\n",
    "            print(f\" Source results directory not found: {source_dir}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\" Generation timed out after 300 seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23ba3b",
   "metadata": {},
   "source": [
    "## Section 5: View Results & Visualization\n",
    "\n",
    "Display the generated IV surfaces and analysis results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Find the most recent results folder for the target date\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"SEARCHING FOR RESULTS FOR {TARGET_DATE}\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "# Look for folders matching TARGET_DATE in demo_results folder\n",
    "matching_dirs = sorted([d for d in RESULTS_FOLDER.glob(f\"{TARGET_DATE}_*\")], reverse=True)\n",
    "\n",
    "# Fallback: Check if results exist in the original condtional_vae/results_date folder\n",
    "fallback_dir = PROJECT_ROOT / \"condtional_vae\" / \"results_date\" / TARGET_DATE\n",
    "\n",
    "if matching_dirs:\n",
    "    results_dir = matching_dirs[0]  # Get the most recent\n",
    "    print(f\" Found results in demo_results: {results_dir.name}\\n\")\n",
    "    source = \"demo_results\"\n",
    "elif fallback_dir.exists():\n",
    "    results_dir = fallback_dir\n",
    "    print(f\" Found results in original location: condtional_vae/results_date/{TARGET_DATE}\\n\")\n",
    "    print(f\" Note: These results were not generated from this notebook run.\")\n",
    "    print(f\"  To save results to demo_results, run Section 4 (IV Surface Generation).\\n\")\n",
    "    source = \"original\"\n",
    "else:\n",
    "    results_dir = None\n",
    "    print(f\" No results found for {TARGET_DATE}\")\n",
    "    print(f\"\\nSearched in:\")\n",
    "    print(f\"  - {RESULTS_FOLDER}\")\n",
    "    print(f\"  - {fallback_dir}\")\n",
    "    print(\"\\nPlease run the IV Surface Generation cell (Section 4) first.\")\n",
    "\n",
    "if results_dir and results_dir.exists():\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"RESULTS FOR {TARGET_DATE}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    # Load and display mean IV surface\n",
    "    mean_iv_file = results_dir / \"mean_iv_surface.csv\"\n",
    "    if mean_iv_file.exists():\n",
    "        df_mean = pd.read_csv(mean_iv_file, index_col=0)\n",
    "        print(\"Mean IV Surface (Implied Volatility %):\")\n",
    "        print(df_mean.round(2))\n",
    "        print()\n",
    "    \n",
    "    # Load and display median IV surface\n",
    "    median_iv_file = results_dir / \"median_iv_surface.csv\"\n",
    "    if median_iv_file.exists():\n",
    "        df_median = pd.read_csv(median_iv_file, index_col=0)\n",
    "        print(\"\\nMedian IV Surface (Implied Volatility %):\")\n",
    "        print(df_median.round(2))\n",
    "        print()\n",
    "    \n",
    "    # Display plots if they exist\n",
    "    plot_files = [\n",
    "        \"atm_term_structure.png\",\n",
    "        \"mean_surface_heatmap.png\",\n",
    "        \"iv_smiles.png\"\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"GENERATED VISUALIZATIONS\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    for plot_file in plot_files:\n",
    "        plot_path = results_dir / plot_file\n",
    "        if plot_path.exists():\n",
    "            print(f\"\\n{plot_file}:\")\n",
    "            img = Image.open(plot_path)\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"{TARGET_DATE} - {plot_file}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # List all files in results directory\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"ALL FILES IN RESULTS DIRECTORY\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    for file in sorted(results_dir.glob(\"*\")):\n",
    "        size = file.stat().st_size / 1024  # KB\n",
    "        print(f\"  {file.name:40s} ({size:8.1f} KB)\")\n",
    "    \n",
    "    if source == \"original\":\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(\"NOTE: Using results from original location\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        print(f\"These results are from: condtional_vae/results_date/{TARGET_DATE}\")\n",
    "        print(f\"To generate fresh results in demo_results, run Section 4.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd84ba3",
   "metadata": {},
   "source": [
    "## Section 7: Interactive LLM Options Assistant\n",
    "\n",
    "Chat with an AI-powered options analyst that can:\n",
    "- Generate IV surfaces for any date\n",
    "- Analyze volatility patterns and market sentiment\n",
    "- Identify trading opportunities\n",
    "- Provide actionable recommendations\n",
    "\n",
    "**Requirements:**\n",
    "- Google Gemini API key (free, no credit card required)\n",
    "- Get your key at: https://aistudio.google.com/app/apikey\n",
    "\n",
    "**Usage:**\n",
    "1. Set your API key: `os.environ['GEMINI_API_KEY'] = 'your-key-here'`\n",
    "2. Run the cell below to start chatting\n",
    "3. Type 'quit' to exit the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9085132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from api.json and run the LLM Options Assistant\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Load API key from api.json\n",
    "api_file = PROJECT_ROOT / \"api.json\"\n",
    "\n",
    "if api_file.exists():\n",
    "    with open(api_file, 'r') as f:\n",
    "        api_data = json.load(f)\n",
    "        os.environ['GEMINI_API_KEY'] = api_data['API_KEY']\n",
    "    print(\" API key loaded from api.json\\n\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"  API KEY FILE NOT FOUND\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nExpected file: {api_file}\")\n",
    "    print(\"\\nCreate api.json with:\")\n",
    "    print('{\\n    \"API_KEY\": \"your-gemini-api-key-here\"\\n}')\n",
    "    print(\"\\nGet your free API key at: https://aistudio.google.com/app/apikey\")\n",
    "    print(\"=\" * 80)\n",
    "    sys.exit(1)\n",
    "\n",
    "# Add the llm_options_assistant directory to path\n",
    "llm_assistant_dir = PROJECT_ROOT / \"llm_options_assistant\"\n",
    "sys.path.insert(0, str(llm_assistant_dir))\n",
    "\n",
    "# Import and run the assistant\n",
    "print(\"=\" * 80)\n",
    "print(\" Starting NIFTY 50 Options Analysis Assistant\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Using script: {llm_assistant_dir / 'options_analyst_gemini.py'}\")\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# Import the main function from the script\n",
    "from options_analyst_gemini import main\n",
    "\n",
    "# Run the interactive assistant\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbd14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0fedc86",
   "metadata": {},
   "source": [
    "## Section 8: Advanced Usage - Batch Generation\n",
    "\n",
    "Generate IV surfaces for multiple dates in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Generate surfaces for multiple dates\n",
    "# Uncomment and customize to use this feature\n",
    "\n",
    "BATCH_GENERATION = False\n",
    "\n",
    "if BATCH_GENERATION:\n",
    "    from datetime import datetime, timedelta\n",
    "    \n",
    "    # Check if model exists\n",
    "    pretrained_model = PROJECT_ROOT / \"llm_options_assistant\" / \"best_model_2025\" / \"cvae_model.pt\"\n",
    "    trained_model = PROJECT_ROOT / \"condtional_vae\" / \"best_model\" / \"cvae_model.pt\"\n",
    "    \n",
    "    if not (pretrained_model.exists() or trained_model.exists()):\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ERROR: No trained model available for batch generation\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"\\nPlease ensure one of the following:\")\n",
    "        print(\"  1. Pre-trained model exists at: llm_options_assistant/best_model_2025/cvae_model.pt\")\n",
    "        print(\"  2. Run Section 3 (CVAE Training) to train a new model\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        # Define date range\n",
    "        start_date = datetime(2025, 10, 1)\n",
    "        end_date = datetime(2025, 11, 10)\n",
    "        \n",
    "        dates_to_generate = []\n",
    "        current = start_date\n",
    "        while current <= end_date:\n",
    "            dates_to_generate.append(current.strftime(\"%Y-%m-%d\"))\n",
    "            current += timedelta(days=1)\n",
    "        \n",
    "        print(f\"\\nGenerating surfaces for {len(dates_to_generate)} dates...\")\n",
    "        print(f\"Date range: {dates_to_generate[0]} to {dates_to_generate[-1]}\")\n",
    "        print(f\"Results will be saved to: {RESULTS_FOLDER}\\n\")\n",
    "        \n",
    "        venv_python = PROJECT_ROOT / \".venv\" / \"bin\" / \"python\"\n",
    "        script_path = PROJECT_ROOT / \"condtional_vae\" / \"generate_iv_surface_by_date.py\"\n",
    "        \n",
    "        results = {}\n",
    "        batch_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        \n",
    "        # Set up environment with proper matplotlib backend\n",
    "        env = os.environ.copy()\n",
    "        env['MPLBACKEND'] = 'Agg'  # Use Agg backend for batch processing\n",
    "        \n",
    "        for idx, date in enumerate(dates_to_generate, 1):\n",
    "            print(f\"\\n[{idx}/{len(dates_to_generate)}] Generating for {date}...\", end=\" \")\n",
    "            \n",
    "            cmd = [\n",
    "                str(venv_python),\n",
    "                str(script_path),\n",
    "                \"--date\", date,\n",
    "                \"--n_samples\", \"50\",  # Fewer samples for batch to speed up\n",
    "                \"--output_dir\", \"results_date\"\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    cmd,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=120,\n",
    "                    cwd=str(PROJECT_ROOT / \"condtional_vae\"),\n",
    "                    env=env  # Pass custom environment\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    # Copy results to results folder\n",
    "                    source_dir = PROJECT_ROOT / \"condtional_vae\" / \"results_date\" / date\n",
    "                    dest_dir = RESULTS_FOLDER / f\"{date}_{batch_timestamp}\"\n",
    "                    \n",
    "                    if source_dir.exists():\n",
    "                        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        for file in source_dir.glob(\"*\"):\n",
    "                            if file.is_file():\n",
    "                                shutil.copy2(file, dest_dir / file.name)\n",
    "                    \n",
    "                    print(\"\")\n",
    "                    results[date] = \"Success\"\n",
    "                else:\n",
    "                    print(\"\")\n",
    "                    results[date] = f\"Failed (code {result.returncode})\"\n",
    "                    \n",
    "            except subprocess.TimeoutExpired:\n",
    "                print(\"â± Timeout\")\n",
    "                results[date] = \"Timeout\"\n",
    "            except Exception as e:\n",
    "                print(f\" {str(e)}\")\n",
    "                results[date] = str(e)\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(\"BATCH GENERATION SUMMARY\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        success_count = sum(1 for v in results.values() if v == \"Success\")\n",
    "        print(f\"\\nCompleted: {success_count}/{len(dates_to_generate)}\")\n",
    "        print(f\"Results saved to: {RESULTS_FOLDER}\\n\")\n",
    "        \n",
    "        for date, status in results.items():\n",
    "            symbol = \"\" if status == \"Success\" else \"\"\n",
    "            print(f\"  {symbol} {date}: {status}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Batch generation is DISABLED\")\n",
    "    print(\"\\nTo enable batch generation:\")\n",
    "    print(\"  1. Set BATCH_GENERATION = True\")\n",
    "    print(\"  2. Customize date range (lines below)\")\n",
    "    print(\"  3. Re-run this cell\")\n",
    "    print(f\"\\nResults will be saved to: {RESULTS_FOLDER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abf2388",
   "metadata": {},
   "source": [
    "## Section 9: Pipeline Summary & Notes\n",
    "\n",
    "### Project Overview\n",
    "\n",
    "This notebook orchestrates the **Arbitrage-Free IV Surface Generation Pipeline**, which consists of three main components:\n",
    "\n",
    "1. **Heston Model Calibration**\n",
    "   - Fits single Heston parameters for each trading day\n",
    "   - Uses two-stage optimization (fast + Wasserstein refinement)\n",
    "   - Input: IV surfaces from NIFTY options market\n",
    "   - Output: 5 parameters (kappa, theta, sigma_v, rho, v0) per day\n",
    "\n",
    "2. **Conditional VAE Training** (Optional)\n",
    "   - Trains a variational autoencoder with market conditioning\n",
    "   - Conditions on: VIX, USD/INR, Oil prices, Interest rates, Geopolitical unrest\n",
    "   - Learns latent distribution of Heston parameters\n",
    "   - Pre-trained model available: `llm_options_assistant/best_model_2025/`\n",
    "\n",
    "3. **IV Surface Generation**\n",
    "   - Generates forward-looking IV surfaces for any date\n",
    "   - Conditions on current market state\n",
    "   - Produces 100 sample surfaces with statistics\n",
    "   - Outputs: matrices, plots, PyTorch tensors\n",
    "\n",
    "### Key Features\n",
    "\n",
    " **Current Data:** GDELT unrest index updated to 2025-11-10\n",
    " **Market Data:** India VIX, USD/INR, Crude Oil, US 10Y Yield (via yfinance)\n",
    " **Full Date Range:** 2015-01-01 to 2025-11-10\n",
    " **Pre-trained Model:** Ready for immediate IV surface generation\n",
    " **LLM Assistant:** Interactive AI analyst for options analysis\n",
    " **Error Handling:** Graceful fallbacks for missing data\n",
    "\n",
    "### How to Use\n",
    "\n",
    "1. **Run Heston Calibration:** Execute Section 2 (takes 10-30 minutes) - Optional if using existing\n",
    "2. **Skip CVAE Training:** Use pre-trained model (Section 3)\n",
    "3. **Generate Surfaces:** Set date in Section 4, run the cell\n",
    "4. **View Results:** Section 5 displays matrices and plots\n",
    "5. **Chat with AI:** Section 7 provides interactive options analysis\n",
    "6. **Batch Generation:** Optional batch processing (Section 8)\n",
    "\n",
    "### Typical Workflow\n",
    "\n",
    "```\n",
    "Setup (Section 1)\n",
    "    â†“\n",
    "Heston Calibration (Section 2) [Optional - uses existing]\n",
    "    â†“\n",
    "CVAE Training (Section 3) [Skip if using pre-trained]\n",
    "    â†“\n",
    "IV Surface Generation (Section 4) [Main output]\n",
    "    â†“\n",
    "Visualize Results (Section 5)\n",
    "    â†“\n",
    "Chat with LLM Assistant (Section 7) [Interactive analysis]\n",
    "```\n",
    "\n",
    "### File Structure\n",
    "\n",
    "```\n",
    "/project_root/\n",
    "â”œâ”€â”€ calibration_single_heston/\n",
    "â”‚   â”œâ”€â”€ run_single_heston_calibration.py\n",
    "â”‚   â””â”€â”€ NIFTY_heston_single_params_tensor.pt (output)\n",
    "â”œâ”€â”€ condtional_vae/\n",
    "â”‚   â”œâ”€â”€ train_cvae.py\n",
    "â”‚   â”œâ”€â”€ generate_iv_surface_by_date.py\n",
    "â”‚   â””â”€â”€ results_date/ (generated surfaces)\n",
    "â”œâ”€â”€ llm_options_assistant/\n",
    "â”‚   â”œâ”€â”€ best_model_2025/cvae_model.pt (pre-trained model)\n",
    "â”‚   â””â”€â”€ options_analyst_gemini.py (LLM assistant)\n",
    "â”œâ”€â”€ demo_results/ (notebook outputs)\n",
    "â””â”€â”€ Scripts_Orchestration.ipynb (this notebook)\n",
    "```\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**Issue:** \"Module not found\" errors\n",
    "**Solution:** Ensure venv is activated. Run: `source .venv/bin/activate`\n",
    "\n",
    "**Issue:** \"File not found\" in calibration\n",
    "**Solution:** Check that `nifty_filtered_surfaces.pickle` exists in project root\n",
    "\n",
    "**Issue:** No market data available\n",
    "**Solution:** Ensure yfinance can reach internet. Check ticker symbols (^INDIAVIX, EURINR=X, etc.)\n",
    "\n",
    "**Issue:** GDELT data not found\n",
    "**Solution:** Run `condtional_vae/fetch_and_compute_unrest_index.py` to update\n",
    "\n",
    "**Issue:** LLM Assistant not working\n",
    "**Solution:** Get free Gemini API key from https://aistudio.google.com/app/apikey\n",
    "\n",
    "### References\n",
    "\n",
    "- Heston Model: Two-factor stochastic volatility model\n",
    "- Conditional VAE: Learns conditional distribution of parameters given market state\n",
    "- GDELT Data: Geopolitical event database for sentiment/unrest index\n",
    "- Wasserstein Metric: Optimal transport distance for distribution matching\n",
    "- Google Gemini: Free LLM API for options analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1d6736",
   "metadata": {},
   "source": [
    "## Section 10: Results Management\n",
    "\n",
    "View all generated results and organize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"RESULTS FOLDER CONTENTS\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "print(f\"Results Location: {RESULTS_FOLDER}\\n\")\n",
    "\n",
    "if RESULTS_FOLDER.exists():\n",
    "    # Get all subdirectories\n",
    "    subdirs = sorted([d for d in RESULTS_FOLDER.iterdir() if d.is_dir()], reverse=True)\n",
    "    \n",
    "    if subdirs:\n",
    "        print(f\"Found {len(subdirs)} result directories:\\n\")\n",
    "        \n",
    "        for subdir in subdirs:\n",
    "            # Parse directory name\n",
    "            parts = subdir.name.rsplit('_', 2)  # Split from right to get date and timestamp\n",
    "            dir_name = subdir.name\n",
    "            \n",
    "            # Count files\n",
    "            files = list(subdir.glob(\"*\"))\n",
    "            file_count = len(files)\n",
    "            total_size = sum(f.stat().st_size for f in files if f.is_file()) / 1024 / 1024  # MB\n",
    "            \n",
    "            print(f\" {dir_name}/\")\n",
    "            print(f\"   Files: {file_count}, Size: {total_size:.2f} MB\")\n",
    "            \n",
    "            # List files\n",
    "            for file in sorted(files):\n",
    "                size = file.stat().st_size / 1024\n",
    "                print(f\"     â€¢ {file.name:35s} ({size:8.1f} KB)\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"No results generated yet in demo_results folder.\")\n",
    "        print(\"\\nRun the IV Surface Generation cell (Section 4) to create results.\")\n",
    "        \n",
    "        # Check for results in original location\n",
    "        original_results = PROJECT_ROOT / \"condtional_vae\" / \"results_date\"\n",
    "        if original_results.exists():\n",
    "            original_subdirs = list(original_results.glob(\"*\"))\n",
    "            if original_subdirs:\n",
    "                print(f\"\\n Found {len(original_subdirs)} result(s) in original location:\")\n",
    "                print(f\"  {original_results}\")\n",
    "                print(\"\\nThese can be viewed in Section 5 (View Results) as fallback.\")\n",
    "else:\n",
    "    print(f\"Results folder not yet created: {RESULTS_FOLDER}\")\n",
    "    print(\"It will be created when you first run the IV Surface Generation.\")\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"HOW TO USE RESULTS\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "print(f\"1. Results are saved in: {RESULTS_FOLDER}\")\n",
    "print(f\"2. Each run creates a timestamped folder: DATE_YYYYMMDD_HHMMSS/\")\n",
    "print(f\"3. Inside each folder:\")\n",
    "print(f\"   â€¢ iv_surfaces.pt - PyTorch tensor with samples\")\n",
    "print(f\"   â€¢ mean_iv_surface.csv - Average IV surface (8x21 matrix)\")\n",
    "print(f\"   â€¢ median_iv_surface.csv - Median IV surface (8x21 matrix)\")\n",
    "print(f\"   â€¢ atm_term_structure.png - Term structure plot\")\n",
    "print(f\"   â€¢ mean_surface_heatmap.png - IV heatmap visualization\")\n",
    "print(f\"   â€¢ iv_smiles.png - Volatility smile across maturities\")\n",
    "print(f\"   â€¢ execution_log_*.log - Detailed execution log\")\n",
    "print(f\"\\n4. You can download/share any result folder directly\")\n",
    "print(f\"\\n5. Fallback: If no demo_results exist, Section 5 will use results from:\")\n",
    "print(f\"   condtional_vae/results_date/ (if available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7510159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
